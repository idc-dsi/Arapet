{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702ad4d8-3e3a-4f37-8834-f5c544058eae",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Arapet train example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5cd25b-3f9a-4661-b8a2-a85bb6b3c4cf",
   "metadata": {},
   "source": [
    "Some general configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c020ab50-16d9-4db0-a059-151169c3661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproccess import simple_clean\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "%config Completer.use_jedi = False\n",
    "import pickle,os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0' #\"0,1,2,3\"\n",
    "\n",
    "seed = 42\n",
    "\n",
    "task_name = \"arabic_multilabel\"\n",
    "data_dir = \"data/raw_data\"\n",
    "pet_data = \"data/few_shot\"\n",
    "label_column = \"S2P_label\"\n",
    "label_names = ['no_ref','neutral','positive','negative']\n",
    "base_model_name = \"UBC-NLP/MARBERT\"\n",
    "output_model_dir = \"models/personal_sentiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d39f3-b254-49cb-b999-38468897b797",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec296993-e7e4-4526-a864-db9224d7b318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6570033d04c4d20b9b25d2c4eb438a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f943da4ca0aa4cc7bb8334c8c5718d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b20ce887d74503b7a7686759534b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f0e071b23b47cda2b510f5ebb2e72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "def clean_data(df,columns_to_clean=None,extra_tokens_num=0):\n",
    "    df[\"len_combined\"] = 0\n",
    "    for col_name in columns_to_clean:\n",
    "        clean_text_list = []\n",
    "        clean_text_len = []\n",
    "        for text in tqdm(list(df[col_name])):\n",
    "            clean_text = simple_clean(text)\n",
    "            clean_text_list.append(clean_text)\n",
    "            clean_text_len.append(len(tokenizer.tokenize(clean_text)))     \n",
    "        df[f\"clean_{col_name}\"] = clean_text_list\n",
    "        df[f\"len_clean_{col_name}\"] = clean_text_len\n",
    "        df[\"len_combined\"] = df[\"len_combined\"] + df[f\"len_clean_{col_name}\"]\n",
    "    df[\"len_combined\"] = df[\"len_combined\"] + extra_tokens_num\n",
    "    print(\"Max len_combined: \",df[\"len_combined\"].max())\n",
    "    return df\n",
    "\n",
    "def MakeForPET(data,save_to,maping=None,cut_size=False,save=True):\n",
    "    columns_to_clean = ['main_post_ar','response_post_ar']\n",
    "    df = clean_data(data.copy(),columns_to_clean)\n",
    "    if maping:\n",
    "        df[label_column] = df[label_column].map(maping)\n",
    "    if cut_size:\n",
    "        print(\"cutting size...\")\n",
    "        print(df.describe()[['len_combined','len_clean_main_post_ar','len_clean_response_post_ar']])\n",
    "        df = df.loc[(df.len_clean_main_post_ar<85)&(df.len_clean_response_post_ar<85)&(df.len_clean_main_post_ar>5)&(df.len_clean_response_post_ar>5)&(df.len_combined<143)].copy()\n",
    "    print(df.describe()[['len_combined','len_clean_main_post_ar','len_clean_response_post_ar']])\n",
    "    if save:\n",
    "        saving_dir = f\"{pet_data}/{save_to}\"\n",
    "        print(\"save to: \",saving_dir)\n",
    "        df[[\"clean_main_post_ar\",\"clean_response_post_ar\",label_column]].to_csv(saving_dir,index=False,header=False)\n",
    "    print(\"--\"*30,\"\\n\")\n",
    "    return df\n",
    "\n",
    "def MakeLabel(file_name=None):\n",
    "    with open(f'{data_dir}/{file_name}.pickle','rb') as f:\n",
    "        df = pickle.load(f)\n",
    "        try:\n",
    "            df[label_column] = df[\"Sent2Person_1\"].copy()\n",
    "            df.dropna(subset=[label_column],inplace=True)\n",
    "        except:\n",
    "            print(\"unlabeled data! inserting dummy labels\")\n",
    "            df[label_column] = \"unlabeled\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952147ce-bd03-4276-bbbf-04b414c32b79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlabeled data! inserting dummy labels\n"
     ]
    }
   ],
   "source": [
    "train_df = MakeLabel(\"train_df_200\")\n",
    "test_df = MakeLabel(\"test_df_1589\")\n",
    "df_silver = MakeLabel(\"df_silver\")\n",
    "unl_df = MakeLabel(\"full_df_unlabeled\")\n",
    "unl_df = unl_df.loc[unl_df.data==\"unlabeled\"]\n",
    "unl_df = pd.concat([df_silver,unl_df]).sample(frac=1,random_state=seed)#.drop(label_column,axis=1)\n",
    "unl_df[label_column] = \"unlabeled\"\n",
    "\n",
    "train_pet = MakeForPET(train_df,\"train.csv\")    \n",
    "test_pet = MakeForPET(test_df,\"test.csv\")\n",
    "dev_pet = MakeForPET(test_df,\"dev.csv\")\n",
    "unl_pet = MakeForPET(unl_df,\"unlabeled.csv\",cut_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80eccbd7-151e-42f3-af4a-1c4d1fa33966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_ref      462\n",
       "negative    423\n",
       "positive    410\n",
       "neutral     294\n",
       "Name: S2P_label, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pet[label_column].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a0504e-dedb-4e64-95a9-55937c6f48a6",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3702a-ba2b-4f54-9d57-621b9d0bb147",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 cli.py \\\n",
    "--method ipet \\\n",
    "--pattern_ids 0 1 2 \\\n",
    "--ipet_scale_factor 5 \\\n",
    "--split_examples_evenly \\\n",
    "--data_dir $data_dir \\\n",
    "--model_type bert \\\n",
    "--model_name_or_path $base_model_name \\\n",
    "--pet_max_seq_length 160 \\\n",
    "--sc_repetitions 2 \\\n",
    "--task_name $task_name \\\n",
    "--output_dir $output_model_dir \\\n",
    "--overwrite_output_dir \\\n",
    "--pet_num_train_epochs 3 \\\n",
    "--sc_num_train_epochs 2 \\\n",
    "--pet_repetitions 3 \\\n",
    "--ipet_generations 3 \\\n",
    "--pet_per_gpu_train_batch_size 4 \\\n",
    "--pet_per_gpu_eval_batch_size 64 \\\n",
    "--pet_per_gpu_unlabeled_batch_size 64 \\\n",
    "--sc_per_gpu_train_batch_size 4 \\\n",
    "--sc_per_gpu_eval_batch_size 64 \\\n",
    "--sc_per_gpu_unlabeled_batch_size 64 \\\n",
    "--warmup_steps 0 \\\n",
    "--logging_steps 100 \\\n",
    "--do_train \\\n",
    "--do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34342cf-ea04-4c46-95bc-8555079f5f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "503997a7-e012-4fa1-9610-0382fa986369",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d5d89d-df33-4f63-8d7e-8a3eb703443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import pickle,os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd221d63-0466-41c5-b653-56284e7bba47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_ref', 'positive', 'negative', 'neutral']\n",
      "final/ \n",
      " ------------------------------------------------------------------------------------------\n",
      "iteration: final/p0-i0\n",
      "1589\n",
      "\n",
      " iteration no.  0 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83       423\n",
      "     neutral       0.77      0.61      0.68       756\n",
      "    positive       0.54      0.83      0.65       410\n",
      "\n",
      "    accuracy                           0.71      1589\n",
      "   macro avg       0.73      0.74      0.72      1589\n",
      "weighted avg       0.74      0.71      0.71      1589\n",
      "\n",
      "iteration: final/p0-i1\n",
      "1589\n",
      "\n",
      " iteration no.  1 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83       423\n",
      "     neutral       0.77      0.61      0.68       756\n",
      "    positive       0.54      0.83      0.65       410\n",
      "\n",
      "    accuracy                           0.71      1589\n",
      "   macro avg       0.73      0.74      0.72      1589\n",
      "weighted avg       0.74      0.71      0.71      1589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install jsonlines\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "model_dir = output_model_dir # \"models/personal_sentiment\"\n",
    "eval_df = pd.read_csv(\"data/few_shot/test.csv\",header=None)\n",
    "eval_df.columns = [\"sentence1\",\"sentence2\",\"label\"]\n",
    "labels = list(eval_df.label.unique())\n",
    "print(labels)\n",
    "\n",
    "\n",
    "map_3_class = True\n",
    "map_4to3 = {'no_ref':\"neutral\",'neutral':\"neutral\",'positive':\"positive\",'negative':\"negative\"}\n",
    "\n",
    "#for g in [\"\",\"g0/\",\"g1/\",\"g2/\",\"final/\"]:\n",
    "for g in [\"final/\"]: \n",
    "    print(g,\"\\n\",\"---\"*30)\n",
    "    for pattern in [0,1,2,3]:\n",
    "        for iteration in [0,1,2,3]:\n",
    "            final = f\"{model_dir}/{g}p{pattern}-i{iteration}/predictions.jsonl\"\n",
    "            my_file = Path(final)\n",
    "            if my_file.is_file():\n",
    "                predictions=[]\n",
    "                with jsonlines.open(final) as f:\n",
    "                    for line in f.iter():\n",
    "                        predictions.append(line['label'])\n",
    "                print(f\"iteration: {g}p{pattern}-i{iteration}\")\n",
    "                print(len(predictions))\n",
    "                eval_df['predictions'] = predictions\n",
    "                if map_3_class:\n",
    "                    eval_df['predictions']=eval_df['predictions'].map(map_4to3)\n",
    "                    eval_df['label']=eval_df['label'].map(map_4to3)\n",
    "                print(\"\\n iteration no. \",iteration,\"\\n\")\n",
    "                print(classification_report(y_true=list(eval_df['label']), y_pred=list(eval_df['predictions'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc5e6e-f7a2-4f9b-a92d-0547fc197888",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Arapet Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad54c3-6fe5-4c64-8c77-f813c4df2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on Colab\n",
    "\"\"\"\n",
    "!git clone https://github.com/idc-dsi/Arapet.git\n",
    "%cd Arapet\n",
    "!pip install -r requirements.txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920bec39-3466-413f-8ae5-e0509b448cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproccess import simple_clean\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "%config Completer.use_jedi = False\n",
    "import pickle,os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import torch\n",
    "from pet import InputExample\n",
    "from pet.ArapetModel import InitArapetModel\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "model = InitArapetModel()\n",
    "model.model.to(device)\n",
    "label_map = {0:\"no_personal_sentiment\",1:\"no_personal_sentiment\",2:\"good_personal\",3:\"bad_personal\"}\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]='0' #\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71dfb108-0482-4701-b4c1-dbeff7e9e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_instance(main_post=None,response_post=None):\n",
    "    if main_post and response_post:\n",
    "        data = [InputExample(guid=0,text_a=simple_clean(main_post),text_b=simple_clean(response_post))]\n",
    "    else:\n",
    "        if main_post:\n",
    "            text = main_post\n",
    "        else:\n",
    "            text = response_post\n",
    "        print(\"Warning! for best performance please insert both 'main_post' and 'response_post'!\")\n",
    "        data = [InputExample(guid=0,text_a=simple_clean(text),text_b=None)]\n",
    "    \n",
    "    prediction = model.eval(data, device=device)['logits'].argmax()\n",
    "    label = label_map[prediction]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e913d4-621c-43c2-8317-2bf49c8952b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 20:41:29,616 - INFO - wrapper - Writing example 0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "2021-12-11 20:41:29,619 - INFO - wrapper - --- Example 0 ---\n",
      "2021-12-11 20:41:29,619 - INFO - wrapper - input_ids         = ['[CLS]', 'هل', 'تمتلك', 'صديق', 'منذ', '5', 'سنوات', '?', '[SEP]', 'عندي', '3', 'اصدقاء', 'من', 'ال20', '##0', '##3', '.', 'وصديق', 'من', 'ا', '##ل', '2009', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "attention_mask    = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids    = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "mlm_labels        = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "logits            = [-1]\n",
      "label             = -100\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'no_personal_sentiment'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = \"هل تمتلك صديق منذ 5 سنوات ؟\"\n",
    "response = \"عندي 3 أصدقاء من ال2003 . وصديق من ال 2009\"\n",
    "\n",
    "predict_instance(post,response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a14147-a960-4004-af63-30f7aa861602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 20:41:29,777 - INFO - wrapper - Writing example 0\n",
      "2021-12-11 20:41:29,779 - INFO - wrapper - --- Example 0 ---\n",
      "2021-12-11 20:41:29,780 - INFO - wrapper - input_ids         = ['[CLS]', 'خربوا', 'البلد', 'وش', '##لوه', '،', 'وعملوا', 'شعب', '##وية', 'وقفت', 'كل', 'المشاريع', 'المني', '##حة', 'والمنت', '##جة', '؛', 'اليوم', 'عم', 'يشوفوا', 'وين', 'في', 'شي', 'محل', 'منت', '##عش', 'ومز', '##ده', '##ر', '،', 'بدهم', 'يوذ', '##وه', '.', '[SEP]', 'في', 'مراية', 'امامك', 'انت', 'عمت', '##حكي', '.', '.', '.', 'انت', 'شو', 'عملت', 'للبلد', '?', 'كهربا', 'ما', 'في', 'سد', '##ود', 'وهمية', '.', '.', '.', 'ما', 'خلوني', 'وما', 'وما', 'وما', '.', '.', '.', 'فاشل', 'كبير', 'انت', 'ارحم', 'الناس', 'من', 'هيك', 'كلام', '.', '.', '.', 'الناس', 'عارف', '##تك', 'على', 'حقيقتك', 'انك', 'انسان', 'فاشل', 'وسبب', 'مباشر', 'من', 'ازمة', 'لبنان', '.', 'يجب', 'ان', 'تحاكم', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "attention_mask    = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids    = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "mlm_labels        = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "logits            = [-1]\n",
      "label             = -100\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bad_personal'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = \"خرّبوا البلد وشلّوه، وعملوا شعبويّة وقّفت كل المشاريع المنيحة والمنتجة؛ اليوم عم يشوفوا وين في شي محل منتعش ومزدهر، بدّهم يؤذوه.\"\n",
    "response = \"@Gebran_Bassil في مراية امامك انت عمتحكي ... انت شو عملت للبلد ؟ كهربا ما في  سدود وهمية ..... ما خلوني وما وما وما .... فاشل كبير انت ارحم الناس من هيك كلام ...الناس عارفتك على حقيقتك انك انسان فاشل  وسبب مباشر من ازمة لبنان .يجب ان تحاكم\"\n",
    "\n",
    "predict_instance(post,response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31285a-97fe-463e-a5aa-b7bc6b78f496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
